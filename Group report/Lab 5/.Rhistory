data11$Day_of_year <- Gb
stat[b] <- stats(data11,1:n)
}
return(stat)
}
stat <- permutation_test(B=2000,data1)
stat0 <- stats(data1,1:nrow(data1))
print (c( stat0 ,mean(abs(stat)>=abs(stat0)) ))
?boot
boot.ci(myboot)
print (c( stat0 ,mean(stat>=stat0) ))
)
print (c( stat0 ,mean(abs(stat)>=abs(stat0)) ))
## step (c)
sapply(seq(0.2,10,0.1), fun)
fun <- function(a){
## step (a)
n <- 366
b <- rnorm(n, mean=183, sd = 10)
X <- data1$Day_of_year
Y <- sapply(1:n,function(i){
t <- min(a*X[i]+b[i],366)
t <- max(0,t)
})
data15 <- data.frame(Day_of_year=X,Draft_No=Y)
## step (b)
stat <- permutation_test(B=200, data15)
stat0 <- stats(data15,1:n)
return(c( stat0 ,mean(abs(stat)>=abs(stat0)) ))
}
fun(a=0.1)
## step (c)
sapply(seq(0.2,10,0.1), fun)
## step (c)
result <- sapply(seq(0.2,10,0.1), fun)
print(result)
dim(result)
?sapply
result<- data.frame(alpha=seq(0.2,10,0.1), p=result[2,])
ggplot(data = result,aes(x=alpha,y=p))+
geom_line()
rm(list = ls())
data2 = read.csv2("prices1.csv")
Sys.setlocale(locale = "English")
knitr::opts_chunk$set(echo = TRUE, out.height = "300px")
# libraries used in this lab
library(ggplot2)
#install.packages("boot") # to create booststarp
library(boot)
# calculate the mean of the price
price_mean = mean(data2$Price) # 1080.473
cols <- c("Mean"="#FF6633")
# create the plot - hist + distribution + mean
ggplot(data = data2, aes(x = Price)) +
#geom_histogram(color = "#33CCFF", fill = "#33CCFF") +
ggtitle("Histogram of Price") +
geom_vline(aes(xintercept = price_mean, color = "Mean")) +
geom_histogram(aes(y=..density..),
colour="black",
fill="white",
bins=30)+
geom_density(alpha=.2, fill="#FF6666")
# geom_density(kernel = "poisson") create a possion distribution
head(data2)
# create the plot - hist + distribution + mean
ggplot(data = data2, aes(x = Price)) +
#geom_histogram(color = "#33CCFF", fill = "#33CCFF") +
ggtitle("Histogram of Price") +
geom_vline(aes(xintercept = price_mean, color = "Mean",size=3)) +
geom_histogram(aes(y=..density..),
colour="black",
fill="white",
bins=30)+
geom_density(alpha=.2, fill="#FF6666")
# create the plot - hist + distribution + mean
ggplot(data = data2, aes(x = Price)) +
#geom_histogram(color = "#33CCFF", fill = "#33CCFF") +
ggtitle("Histogram of Price") +
geom_vline(aes(xintercept = price_mean, color = "Mean",size=2)) +
geom_histogram(aes(y=..density..),
colour="black",
fill="white",
bins=30)+
geom_density(alpha=.2, fill="#FF6666")
# create the plot - hist + distribution + mean
ggplot(data = data2, aes(x = Price)) +
#geom_histogram(color = "#33CCFF", fill = "#33CCFF") +
ggtitle("Histogram of Price") +
geom_vline(aes(xintercept = price_mean, color = "Mean",size=1)) +
geom_histogram(aes(y=..density..),
colour="black",
fill="white",
bins=30)+
geom_density(alpha=.2, fill="#FF6666")
# create the plot - hist + distribution + mean
ggplot(data = data2, aes(x = Price)) +
#geom_histogram(color = "#33CCFF", fill = "#33CCFF") +
ggtitle("Histogram of Price") +
geom_vline(aes(xintercept = price_mean, color = "Mean"),size=1) +
geom_histogram(aes(y=..density..),
colour="black",
fill="white",
bins=30)+
geom_density(alpha=.2, fill="#FF6666")
# create the plot - hist + distribution + mean
ggplot(data = data2, aes(x = Price)) +
#geom_histogram(color = "#33CCFF", fill = "#33CCFF") +
ggtitle("Histogram of Price") +
geom_vline(aes(xintercept = price_mean, color = "Mean"),size=1.5) +
geom_histogram(aes(y=..density..),
colour="black",
fill="white",
bins=30)+
geom_density(alpha=.2, fill="#FF6666")
# calculate the mean of the price
price_mean = mean(data2$Price) # 1080.473
# create the plot - hist + distribution + mean
ggplot(data = data2, aes(x = Price)) +
#geom_histogram(color = "#33CCFF", fill = "#33CCFF") +
ggtitle("Histogram of Price") +
geom_vline(aes(xintercept = price_mean, color = "Mean"),size=1.5) +
geom_histogram(aes(y=..density..),
colour="black",
fill="white",
bins=30)+
geom_density(alpha=.2, fill="#FF6666")
# geom_density(kernel = "poisson") create a possion distribution
price_mean
# function - estiamte mean
stat1 <- function(data,vn){
data = as.data.frame(data[vn,])
return(mean(data$Price))
}
set.seed(123456)
res1 = boot(data2, stat1, R=1000)
res1
?boot.ci
# 95% confidence interval mean price
# --- bootstrap percentile, bootstrap BCa, and firstâ€“order normal approximation
print(boot.ci(res1,type = c("perc", "bca", "norm")))
#  norm
# plot
plot(res1)
# # the two functions does not work
# plot.boot(res)
# print.bootci(res)
length(res1$t)
# bias correcred estimator
2*res1$t0-mean(res1$t)
var(res1$t)
res1$?boot
?boot
# bias correcred estimator
2*res1$t0-mean(res1$t)
# variance of mean price (output of statistic)
var(res1$t)
plot.boot(res1)
?plot.boot
plot(res1)
B=1000
# bias correcred estimator
2*res1$t0-mean(res1$t)
# variance of mean price (output of statistic)
1/(B-1)*sum((res1$t-mean(res1$t))^2 )
var(res1$t)
# Uncertainty estimation: variance of estimator
# - Bootstrap
stat2 = function(data, vn){
data = data[vn]
result = (1/(length(data) -1)) * sum((data - mean(data))^2)
return(result)
}
set.seed(123456)
res2 = boot(res1$t, stat2, R=1000)
res2
# bias correcred estimator
2*res1$t0-mean(res1$t)
# variance of mean price (output of statistic)
1/(B-1)*sum((res1$t-mean(res1$t))^2 )
n = nrow(data2)
constant = 1/(n*(n-1))
T_i_star = c()
for (i in 1:n) {
T_i_star[i] = n * mean(data2$Price) - (n-1) * mean(data2[-i,1])
}
J_T = (1/n) * sum(T_i_star)
Var_T_jackknife = constant * sum((T_i_star - J_T)^2)
Var_T_jackknife
n = nrow(data2)
constant = 1/(n*(n-1))
T_i_star = sapply(1:n, function(i){
n * mean(data2$Price) - (n-1) * mean(data2[-i,1])
})
J_T = (1/n) * sum(T_i_star)
Var_T_jackknife = constant * sum((T_i_star - J_T)^2)
Var_T_jackknife
# bias correcred estimator
2*res1$t0-mean(res1$t)
# variance of mean price (output of statistic)
var_boot <- 1/(B-1)*sum((res1$t-mean(res1$t))^2 )
var_boot
table = data.frame(boostrap = var_boot, jackknife= Var_T_jackknife)
knitr::kable(table)
?jackknife
library(bootstrap)
?jackknife
install.packages("bootstrap")
library(bootstrap)
?jackknife
?jackknife
res2 <- jackknife(data2$Price,stat1)
# function - estiamte mean
stat1 <- function(data,vn){
return(mean(data[vn,]$Price))
}
B=1000
set.seed(123456)
res1 = boot(data2, stat1, R=B)
res1
library(bootstrap)
res2 <- jackknife(data2$Price,stat1)
?jackknife
res2 <- jackknife(data=data2$Price,stat1)
res2 <- jackknife(xtheta==data2$Price,stat1)
res2 <- jackknife(x=data2$Price,theta=stat1)
data2$Price
my.mean <- function(x, indices) {
return(mean(x[indices]))
}
require("bootstrap")
res1 = jackknife(data2$Price, my.mean)
# function - estiamte mean
stat1 <- function(x,vn){
return(mean(x[vn,]$Price))
}
B=1000
set.seed(123456)
res1 = boot(data2, stat1, R=B)
res1
res2 <- jackknife(x=data2$Price,theta=stat1)
res2 <- jackknife(x=data2,stat1)
res2 <- jackknife(data2,stat1)
res2
# function - estiamte mean
stat1 <- function(vec,vn){
return(mean(vec[vn]))
}
B=1000
set.seed(123456)
res1 = boot(data2$Price, stat1, R=B)
res1
# bias correcred estimator
2*res1$t0-mean(res1$t)
# variance of mean price (output of statistic)
var_boot <- 1/(B-1)*sum((res1$t-mean(res1$t))^2 )
var_boot
# default is a 95% confidence interval
print(boot.ci(res1, type = c("perc", "bca", "norm")))
plot(res1)
library(bootstrap)
res2 <- jackknife(x=data2$Price,stat1)
res2$jack.values
mean(res2$jack.values)
n = nrow(data2)
constant = 1/(n*(n-1))
T_i_star = sapply(1:n, function(i){
n * mean(data2$Price) - (n-1) * mean(data2[-i,1])
})
J_T = (1/n) * sum(T_i_star)
Var_T_jackknife = constant * sum((T_i_star - J_T)^2)
Var_T_jackknife
res2$jack.bias
res1
res2
res1
ci=boot.ci(res1, type = c("perc", "bca", "norm"))
ci
ci$normal
plot(ci)
ci@x
ci
summary(ci)
ci$call
table2 <- rbind(norm=ci$normal,percent=ci$percent,bca=ci$bca)
table2 <- data.frame(norm=ci$normal,percent=ci$percent,bca=ci$bca)
knitr::kable(t(table2))
table2
table2 <- rbind(ci$normal,ci$percent,ci$bca)
ci$normal
ci$bca
ci$percent
?boot.ci
bca<-ci$bca
percent<-ci$percent
norm<-ci$normal
bca
percent
norm
`Len. confidence interval`=c(percent[5]-percent[4],bca[5]-bca[4],norm[3]-norm[2])
`Len. confidence interval`
intervals = rbind(percent[4:5],bca[4:5],norm[2:3])
intervals
`Len. confidence interval`=intervals[,2]-intervals[,1]
`Len. confidence interval`=intervals[,2]-intervals[,1]
`esti. mean`=intervals[,1]+`Len. confidence interval`/2
`Len. confidence interval`
`esti.mean`
`esti. mean`
bca<-ci$bca
percent<-ci$percent
norm<-ci$normal
intervals = rbind(percent[4:5],bca[4:5],norm[2:3])
`Len. confidence interval`=intervals[,2]-intervals[,1]
`esti. mean`=intervals[,1]+`Len. confidence interval`/2
table2 <- data.frame(`Len. confidence interval`,`esti. mean`)
rownames(table2) <- c("percent","bca","norm")
knitr::kable(table2)
bca<-ci$bca
percent<-ci$percent
norm<-ci$normal
intervals = rbind(percent[4:5],bca[4:5],norm[2:3])
`Len. CI`=intervals[,2]-intervals[,1]
`esti. mean`=intervals[,1]+`Len. confidence interval`/2
table2 <- data.frame(`Len. confidence interval`,`esti. mean`)
rownames(table2) <- c("percent","bca","norm")
knitr::kable(table2)
bca<-ci$bca
percent<-ci$percent
norm<-ci$normal
intervals = rbind(percent[4:5],bca[4:5],norm[2:3])
`Len. CI`=intervals[,2]-intervals[,1]
`esti. mean`=intervals[,1]+`Len. confidence interval`/2
table2 <- data.frame(`Len. CI`,`esti. mean`)
rownames(table2) <- c("percent","bca","norm")
knitr::kable(table2)
bca<-ci$bca
percent<-ci$percent
norm<-ci$normal
intervals = rbind(percent[4:5],bca[4:5],norm[2:3])
`Len. CI`=intervals[,2]-intervals[,1]
`esti. mean`=intervals[,1]+`Len. confidence interval`/2
table2 <- data.frame(`Len. CI`,`esti.mean`)
bca<-ci$bca
percent<-ci$percent
norm<-ci$normal
intervals = rbind(percent[4:5],bca[4:5],norm[2:3])
`Len.CI`=intervals[,2]-intervals[,1]
`esti.mean`=intervals[,1]+`Len. confidence interval`/2
table2 <- data.frame(`Len.CI`,`esti.mean`)
rownames(table2) <- c("percent","bca","norm")
knitr::kable(table2)
`Len.CI`=intervals[,2]-intervals[,1]
`Esti.mean`=intervals[,1]+`Len. confidence interval`/2
table2 <- data.frame(`Len.CI`,`Esti.mean`)
rownames(table2) <- c("percent","bca","norm")
knitr::kable(table2)
Sys.setlocale(locale = "English")
knitr::opts_chunk$set(echo = TRUE, out.height = "300px")
# libraries used in this lab
library(ggplot2)
#install.packages("boot") # to create booststarp
library(boot)
# scatterplot
rm(list=ls())
data1 = read.csv2("lottery.csv")
plot_11 = ggplot(data = data1,aes(x = Day_of_year, y = Draft_No)) +
geom_point()
plot_11
# scatterplot
rm(list=ls())
data1 = read.csv2("lottery.csv")
plot_11 = ggplot(data = data1,aes(x = Day_of_year, y = Draft_No),color = "blue") +
geom_point()
plot_11
# scatterplot
rm(list=ls())
data1 = read.csv2("lottery.csv")
plot_11 = ggplot(data = data1,aes(x = Day_of_year, y = Draft_No,color = "blue")) +
geom_point()
plot_11
# scatterplot
rm(list=ls())
data1 = read.csv2("lottery.csv")
plot_11 = ggplot(data = data1,aes(x = Day_of_year, y = Draft_No,color = "Blue")) +
geom_point()
plot_11
Sys.setlocale(locale = "English")
knitr::opts_chunk$set(echo = TRUE, out.height = "300px")
# libraries used in this lab
library(ggplot2)
#install.packages("boot") # to create booststarp
library(boot)
# scatterplot
rm(list=ls())
data1 = read.csv2("lottery.csv")
plot_11 = ggplot(data = data1,aes(x = Day_of_year, y = Draft_No)) +
geom_point(aes(color = "red"))
plot_11
# loess(formula = Draft_No~Day_of_year, data = data1)
plot_11 +
# geom_smooth()` using method = 'loess' and formula 'y ~ x'
geom_smooth(method ="loess", formula = y~x, aes(color="blue")) +
scale_color_discrete(labels=c("expected response",
"scatter points")
)
# use non-parametric bootstrap
# need data = data1, statistic = loess & test stat, R = 2000
stats = function(data,vn){
data<-data[vn,]
# Y=Draft_No & X=Day_of_year
# create the loess regression
reg = loess(Draft_No ~ Day_of_year, data = data)
# the X which owns the max/min Y in original data
X_b = data$Day_of_year[which.max(data$Draft_No)]
X_a = data$Day_of_year[which.min(data$Draft_No)]
# Y_hat(X)
fit_X_b = reg$fitted[X_b]
fit_X_a = reg$fitted[X_a]
# the given test statistic
T_stat = (fit_X_b - fit_X_a) / (X_b-X_a)
return(T_stat)
}
#bootstrap
set.seed(123456)
myboot = boot(data = data1,
statistic = stats,
R = 2000)
# summary
myboot
# plot distribution
# plot(myboot, index = 1)
d <- data.frame(t=myboot$t)
ggplot(data = , aes(x = t)) +
ggtitle("Histogram of t") +
geom_histogram(aes(y=..density..),
colour="black",
fill="white",
bins=100) +
geom_vline(aes(xintercept = mean_t, color = "red"))
ggplot(data = d, aes(x = t)) +
ggtitle("Histogram of t") +
geom_histogram(aes(y=..density..),
colour="black",
fill="white",
bins=100) +
geom_vline(aes(xintercept = mean_t, color = "red"))
ggplot(data = d, aes(x = t)) +
ggtitle("Histogram of t") +
geom_histogram(aes(y=..density..),
colour="black",
fill="white",
bins=100) +
geom_vline(aes(xintercept = mean(d), color = "red"))
d <- data.frame(t=myboot$t)
mean <- mean(d)
ggplot(data = d, aes(x = t)) +
ggtitle("Histogram of t") +
geom_histogram(aes(y=..density..),
colour="black",
fill="white",
bins=100) +
geom_vline(aes(xintercept = mean, color = "red"))
mean <- mean(d,na.rm=TRUE)
ggplot(data = d, aes(x = t)) +
ggtitle("Histogram of t") +
geom_histogram(aes(y=..density..),
colour="black",
fill="white",
bins=100) +
geom_vline(aes(xintercept = mean, color = "red"))
myboot$t
mean(myboot$t)
d <- data.frame(t=myboot$t)
mean_t = mean(myboot$t,na.rm = TRUE)
ggplot(data = d, aes(x = t)) +
ggtitle("Histogram of t") +
geom_histogram(aes(y=..density..),
colour="black",
fill="white",
bins=100) +
geom_vline(aes(xintercept = mean_t, color = "red"))
size=1.5
ggplot(data = d, aes(x = t)) +
ggtitle("Histogram of t") +
geom_histogram(aes(y=..density..),
colour="black",
fill="white",
bins=100) +
geom_vline(aes(xintercept = mean_t, color = "red"),size=1.5)
# calculate the p-value
# null hypothesis: T>=0, hv tendancy
p_val = mean(myboot$t>=0, na.rm = TRUE)
p_val
set.seed(123456)
permutation_test <- function(B, data1){
n = dim(data1)[1]
stat = numeric(B)
for(b in 1:B){
# randoming X
Gb = sample(data1$Day_of_year, n)
data11 <- data1
data11$Day_of_year <- Gb
stat[b] <- stats(data11,1:n)
}
return(stat)
}
stat <- permutation_test(B=2000, data1)
stat0 <- stats(data1,1:nrow(data1))
print (c( stat0 ,mean(abs(stat)>=abs(stat0)) ))
# 1.3 t random, p cannot say it is non-random
# 1.4 p cannot say it is random
# 1.5 ensure the test statistic can show randomness

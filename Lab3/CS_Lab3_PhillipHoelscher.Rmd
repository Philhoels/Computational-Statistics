---
title: "Computer Lab 3 Computational Statistics"
author: "Phillip H??lscher"
date: "1 2 2019"
output: 
  pdf_document:
    toc: true 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r,echo=FALSE, warning=FALSE}
# libraries used
library(ggplot2)
#install.packages("gridExtra") # to put the plots togeter
library(gridExtra)
```

# Question 1: Cluster sampling
```{r}
# clean the environment befor starting a new exercise
rm(list = ls())
```


An opinion pool is assumed to be performed in several locations of Sweden by sending inter- viewers to this location. Of course, it is unreasonable from the financial point of view to visit each city. Instead, a decision was done to use random sampling without replacement with the probabilities proportional to the number of inhabitants of the city to select 20 cities. Explore the file population.xls. Note that names in bold are counties, not cities.


## 1. Import necessary information to R.
```{r}
# set working directory
# use code for encoding
Sys.setlocale("LC_ALL", 'en_US.UTF-8')

# load the data
data = read.csv2("population.csv", encoding = "latin1")
data[,1] <- as.character(data[,1])

``` 

## 2. Use a uniform random number generator 
to create a function that selects 1 city from the whole list by the probability scheme offered above (do not use standard sampling functions present in R).

```{r}
# create new data frame - for selected city
selected_cities = data.frame("Municipality" = integer(), #"Municipality"
                               "Population" = integer()) #"Population"
```


```{r}
# create the select city function - based on max
selectCity = function(data){
  # proportional to the number of inhabitants of the city
  data$proportinalPopulation = data$Population/sum(data$Population)
  # generate random numbers - include to dataset
  data$rn_uniform = runif(n=nrow(data),0,1)
  # probabilities proportional to the number of inhabitants
  data$prob_proportinalPopulation = data$proportinalPopulation * data$rn_uniform
  # take one city - max prob_proportinalPopulation
  city_index = which.max(data$prob_proportinalPopulation)
  # print(data[city_index,][1]) # make the print nicer
  
  return(data[city_index,1])
}


```

## 3. Use the function you have created in step 2 as follows:
(a) Apply it to the list of all cities and select one city 
(b) Remove this city from the list
(c) Apply this function again to the updated list of the cities 
(d) Remove this city from the list
(e) . . . and so on until you get exactly 20 cities.

```{r}
# create a function to select 20 cities
select20cities = function(data){
  cities_remain <- data
  selected_cities <- c()
  for (i in 1:20) {
  selected_city <- selectCity(cities_remain)
  selected_cities <- c(selected_cities,selected_city)
  cities_remain <- cities_remain[-which(cities_remain[,1]==selected_city),]
  }
  return(data.frame(Municipality=selected_cities))
}

```

## 4. Run the program. 
Which cities were selected? What can you say about the size of the
selected cities?
```{r}
# list of all selected cities
selected_cities <- select20cities(data)
idx <- match(selected_cities$Municipality, data[,1])
selected_cities$Population <- data[idx,2]
selected_cities <- selected_cities[order(selected_cities[,2],decreasing = TRUE),]
rownames(selected_cities) <- c()
selected_cities
```

Here you can see the table with the selected cities. 
It can be seen that mainly cities with a high population were selected. 


## 5. Plot one histogram showing the size of all cities of the country.
Plot another histogram showing the size of the 20 selected cities. Conclusions?

```{r}
# histogram - 2 selected cities
histplot_20cities = ggplot(selected_cities, aes(selected_cities$Population))+
  geom_histogram(binwidth=10000) +
  xlab("Population") + ggtitle("Size of the 20 selected cities") +
  scale_x_continuous(labels = scales::comma)
```

```{r}
histplot_cities = ggplot(data, aes(data$Population))+
  geom_histogram(binwidth=10000) +
  xlab("Population") + ggtitle("Size of all cities in Sweden")+
  scale_x_continuous(labels = scales::comma)
```

```{r}
# put the plots together
grid.arrange(histplot_20cities, histplot_cities, ncol = 2)
```

First of all, it can be seen that the four largest cities were selected. 
Accordingly, it also makes sense that cities with about 100000 inhabitants were selected most frequently.

\newpage

# Question 2: Different distributions
```{r}
# clean the environment befor starting a new exercise
rm(list = ls())
```

The double exponential (Laplace) distribution is given by formula:
$$ DE(\mu, \alpha) = \frac{\alpha}{2}exp(-\alpha \mid x - \mu \mid) $$


## 1. Write a code generating double exponential distribution 
DE(0, 1) from Unif(0, 1) by using the inverse CDF method. Explain how you obtained that code step by step. Generate 10000 random numbers from this distribution, plot the histogram and comment whether the result looks reasonable.

Cumulative distribution function of the Laplace probability distribution:
$$ F(x) = \int_{-\infty}^{x}  f(u) \rm du  =\left\{
\begin{array}{c l}	
    \frac{1}{2} \rm exp(\alpha(x - \mu))  & \rm if \enspace  x < \mu\\
     1-\frac{1}{2} \rm exp(-\alpha(x - \mu)) & \rm if \enspace x \ge \mu
\end{array}\right.$$


$$ = \frac{1}{2} + \frac{1}{2}sgn(x-\mu)\big( 1- \rm exp(- \alpha \mid x - \mu \mid) \big) = y  $$

Case for x $x \ge \mu$:
$$ x = \mu - \frac{1}{\alpha} \rm ln(2 - 2y)$$

Case for x $x < \mu$:
$$ x = \mu + \frac{1}{\alpha} \rm ln(2y)$$

We combine into the inverse cumulative distribution function is given by:
$$  x = \mu \rm sgn(x-\mu) \frac{1}{\alpha} \rm ln(1+sgn(x-\mu) - sgn(x-\mu) 2y) = F^{-1}(p)  $$  

If we set sgn(x - $ \mu$ = sgn(y-0.5)):

For x $ \ge \mu$:
$$ 0 \leq \frac{1}{\alpha} \rm ln(2 - 2y) \Leftrightarrow  $$
$$ y \ge \frac{1}{2}$$

And for x $ < \mu$:
$$ 0 > x - \mu = \frac{1}{\alpha} \rm ln(2y)  \Leftrightarrow $$

$$ y < \frac{1}{2}  $$
So we sgn(x - $\mu$) = sgn(y - $\frac{1}{2}$)

We will change the formula to

$$X=F^{-1}(u)=\mu-\frac{\rm{sgn}(u-0.5)}{\alpha}\ln(1-2|u-0.5|)$$ 

```{r}
# generate random numbers
n = 1000
set.seed(12345)
x_rand = runif(n, min = 0, max = 1)

# create data frame for visualization
laplace_data = data.frame("randnom numbers" = x_rand)
ggplot(data = laplace_data, aes(x = randnom.numbers )) + xlab("random number") +
    geom_histogram(aes(y=..density..),
                 colour="black",
                 fill="white",
                 bins=100)+
  geom_density(alpha=.2, fill="#FF6666")
```

```{r}
# calculate function of the inverse CDF
inverse_laplace_distribution = function(mu, alpha, x){
  result = mu-(1/alpha)*sign(x-0.5)*log(1-2*abs(x-0.5))
  return(result)
}
```

```{r}
# create a plot of the inverse cdf
# DE(0,1)
laplace_data2 = data.frame("lp_denst" = inverse_laplace_distribution(0,1,x_rand))

laplace_data = data.frame("randnom numbers" = x_rand)
ggplot(data = laplace_data2, aes(x = lp_denst )) + xlab("random number") +
    geom_histogram(aes(y=..density..),
                 colour="black",
                 fill="white",
                 bins=100)+
  geom_density(alpha=.2, fill="#FF6666")

```



## 2. Use the Acceptance/rejection method 
with DE(0,1) as a majorizing density to generate N(0,1) variables. Explain step by step how this was done. How did you choose constant c in this method? Generate 2000 random numbers N(0,1) using your code and plot the histogram. Compute the average rejection rate R in the acceptance/rejection procedure. What is the expected rejection rate ER and how close is it to R? Generate 2000 num- bers from N (0, 1) using standard rnorm() procedure, plot the histogram and compare the obtained two histograms.






\newpage

# Appendig
```{r ref.label=knitr::all_labels(), echo = T, eval = F}
```

